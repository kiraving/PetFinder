{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e0b357f742e5a2c3d79b2848ade285d09f82dddc"
   },
   "source": [
    "Pretrained Neural Networks like VGG16/VGG19/ResNet/DenseNet are trained on ImageNet which contains 1000-class images. This competition just contains two classes: cat and dog. In this kernel, I want to demonstrate how to build a model with **Pytorch** to classify dog or cat to **Finetuning the convnet**, and then **fix ConvNet to extract image features**. \n",
    "\n",
    "This include four steps:\n",
    "\n",
    "- Build Dog/Cat classify dataset for supervised training.\n",
    "- Prepare dataset for Pytorch.\n",
    "- Fintune pretrained ResNet-18 model.\n",
    "- Fixed ConvNet to extract image features.\n",
    "\n",
    "Reference:\n",
    "\n",
    "- [Extract Image features from pretrained NN](https://www.kaggle.com/christofhenkel/extract-image-features-from-pretrained-nn)\n",
    "- [Transfer Learning Using Pytorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "\n",
    "**Please UPVOTE if you find it useful** :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['breed_labels.csv', 'catdog_folders', 'color_labels.csv', 'densenet-pretrain-with-internet-blocked-12b8d1', 'fatsttext-common-crawl', 'images256', 'keras-applications-weights', 'petfinder-adoption-prediction', 'pytorch-catdog', 'state_labels.csv', 'test', 'train', 'word2vec-google']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from shutil import copyfile\n",
    "print(os.listdir(r\"./input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14993 3948 18941\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'./input/petfinder-adoption-prediction/train/train.csv')\n",
    "test_df = pd.read_csv(r'./input/petfinder-adoption-prediction/test/test.csv')\n",
    "test_df['AdoptionSpeed'] = [-1] * len(test_df)\n",
    "data_df = pd.concat([train_df, test_df], axis=0).reset_index()\n",
    "print(train_df.shape[0], test_df.shape[0], data_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=r'./input/petfinder-adoption-prediction/train_images/'\n",
    "save_dir = r'./input/catdog_folders/'\n",
    "petids = data_df['PetID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = torch.load('resnet18_catdog_1ep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "\timg = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "\tmeans=[0.485, 0.456, 0.406]\n",
    "\tstds=[0.229, 0.224, 0.225]\n",
    "\n",
    "\tpreprocessed_img = img.copy()[: , :, ::-1]\n",
    "\tfor i in range(3):\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "\tpreprocessed_img = \\\n",
    "\t\tnp.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "\tpreprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "\tpreprocessed_img.unsqueeze_(0)\n",
    "\tinput = Variable(preprocessed_img, requires_grad = True)\n",
    "\treturn input.cuda()\n",
    "net = torch.load('resnet18_catdog_1ep.pth')\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0617, -1.4259]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinograd\\Anaconda3_12\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9703, 0.0297]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 000a290e4-1 dog\n",
    "# 00a1f270a-1 cat\n",
    "img = cv2.imread('input/petfinder-adoption-prediction/train_images/00a1f270a-1.jpg', 1)\n",
    "#print(img)\n",
    "#img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "inp = preprocess_image(img)\n",
    "#tryim = load_image('input/petfinder-adoption-prediction/train_images/','86e1089a3')\n",
    "net = model_ft#torch.load('resnet50_trained3.pth')\n",
    "#print(net)\n",
    "\n",
    "net.eval()\n",
    "output = net(inp)\n",
    "print(output) #print output from crossentropy score\n",
    "\n",
    "sm = torch.nn.Softmax()\n",
    "probabilities = sm(output) \n",
    "print(probabilities) #Converted to probabilities #tensor[catness, dogness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3620, -0.2394]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinograd\\Anaconda3_12\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6460, 0.3540]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 000a290e4-1 dog\n",
    "# 00a1f270a-1 cat\n",
    "img = cv2.imread('input/petfinder-adoption-prediction/train_images/000a290e4-1.jpg', 1)\n",
    "#print(img)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "inp = preprocess_image(img)\n",
    "#tryim = load_image('input/petfinder-adoption-prediction/train_images/','86e1089a3')\n",
    "net = model_ft#torch.load('resnet50_trained3.pth')\n",
    "#print(net)\n",
    "\n",
    "net.eval()\n",
    "output = net(inp)\n",
    "print(output) #print output from crossentropy score\n",
    "\n",
    "sm = torch.nn.Softmax()\n",
    "probabilities = sm(output) \n",
    "print(probabilities) #Converted to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['86e1089a3', '6296e909a', '3422e4906', ..., 'd981b6395',\n",
       "       'e4da1c9e4', 'a83d95ead'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_petids = train_df['PetID'].values\n",
    "train_petids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.0952, -4.2838]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinograd\\Anaconda3_12\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9991548e-01 8.4479616e-05]]\n",
      "tensor([[ 3.4180, -2.5629]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "[[0.9974796  0.00252035]]\n",
      "tensor([[-4.1203,  5.3020]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "[[8.0895625e-05 9.9991906e-01]]\n",
      "tensor([[-4.7693,  6.3188]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "[[1.5292559e-05 9.9998474e-01]]\n",
      "tensor([[-4.4899,  6.3032]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "[[2.0540278e-05 9.9997950e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 45.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_prob_catness ={}\n",
    "train_prob_dogness ={}\n",
    "for train_petid in tqdm(train_petids[:5]): \n",
    "    row = data_df.loc[data_df['PetID'] == train_petid, :] \n",
    "    photo_amt = row['PhotoAmt'].values[0] \n",
    "    if photo_amt>0 :#and adoption>=0: \n",
    "        i=1 \n",
    "        img_name = str(train_petid)+'-'+str(i)+'.jpg'\n",
    "        img = cv2.imread(root_dir+img_name, 1)\n",
    "        inp = preprocess_image(img)\n",
    "        output = net(inp) #crossentropy score\n",
    "        sm = torch.nn.Softmax()\n",
    "        probabilities = sm(output) \n",
    "        probabilities = probabilities.cpu().detach().numpy()\n",
    "        print(probabilities)\n",
    "        train_prob_catness[train_petid]=probabilities[0][0]\n",
    "        train_prob_dogness[train_petid]=probabilities[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'86e1089a3': 8.4479616e-05,\n",
       " '6296e909a': 0.002520352,\n",
       " '3422e4906': 0.99991906,\n",
       " '5842f1ff5': 0.99998474,\n",
       " '850a43f90': 0.9999795}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob_dogness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"prob_catness\"] = train_df.PetID.map(train_prob_catness)\n",
    "train_df[\"prob_dogness\"] = train_df.PetID.map(train_prob_dogness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.999915\n",
       "1        0.997480\n",
       "2        0.000081\n",
       "3        0.000015\n",
       "4        0.000021\n",
       "5             NaN\n",
       "6             NaN\n",
       "7             NaN\n",
       "8             NaN\n",
       "9             NaN\n",
       "10            NaN\n",
       "11            NaN\n",
       "12            NaN\n",
       "13            NaN\n",
       "14            NaN\n",
       "15            NaN\n",
       "16            NaN\n",
       "17            NaN\n",
       "18            NaN\n",
       "19            NaN\n",
       "20            NaN\n",
       "21            NaN\n",
       "22            NaN\n",
       "23            NaN\n",
       "24            NaN\n",
       "25            NaN\n",
       "26            NaN\n",
       "27            NaN\n",
       "28            NaN\n",
       "29            NaN\n",
       "           ...   \n",
       "14963         NaN\n",
       "14964         NaN\n",
       "14965         NaN\n",
       "14966         NaN\n",
       "14967         NaN\n",
       "14968         NaN\n",
       "14969         NaN\n",
       "14970         NaN\n",
       "14971         NaN\n",
       "14972         NaN\n",
       "14973         NaN\n",
       "14974         NaN\n",
       "14975         NaN\n",
       "14976         NaN\n",
       "14977         NaN\n",
       "14978         NaN\n",
       "14979         NaN\n",
       "14980         NaN\n",
       "14981         NaN\n",
       "14982         NaN\n",
       "14983         NaN\n",
       "14984         NaN\n",
       "14985         NaN\n",
       "14986         NaN\n",
       "14987         NaN\n",
       "14988         NaN\n",
       "14989         NaN\n",
       "14990         NaN\n",
       "14991         NaN\n",
       "14992         NaN\n",
       "Name: prob_catness, Length: 14993, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"prob_catness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]C:\\Users\\vinograd\\Anaconda3_12\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00962085 0.9903791 ]]\n",
      "[[9.9986374e-01 1.3619923e-04]]\n",
      "[[0.9986753  0.00132468]]\n",
      "[[0.7673059  0.23269409]]\n",
      "[[0.00327893 0.9967211 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 52.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.009621\n",
       "1    0.999864\n",
       "2    0.998675\n",
       "3    0.767306\n",
       "4    0.003279\n",
       "Name: prob_catness, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_petids = test_df['PetID'].values\n",
    "test_prob_catness ={}\n",
    "test_prob_dogness ={}\n",
    "root_dir=r'./input/petfinder-adoption-prediction/test_images/'\n",
    "for test_petid in tqdm(test_petids[:5]): \n",
    "    row = test_df.loc[test_df['PetID'] == test_petid, :] \n",
    "    photo_amt = row['PhotoAmt'].values[0] \n",
    "    if photo_amt>0 :#and adoption>=0: \n",
    "        i=1 \n",
    "        img_name = str(test_petid)+'-'+str(i)+'.jpg'\n",
    "        img = cv2.imread(root_dir+img_name, 1)\n",
    "        inp = preprocess_image(img)\n",
    "        output = net(inp) #crossentropy score\n",
    "        sm = torch.nn.Softmax()\n",
    "        probabilities = sm(output) \n",
    "        probabilities = probabilities.cpu().detach().numpy()\n",
    "        print(probabilities)\n",
    "        test_prob_catness[test_petid]=probabilities[0][0]\n",
    "        test_prob_dogness[test_petid]=probabilities[0][1]\n",
    "test_df[\"prob_catness\"] = test_df.PetID.map(test_prob_catness)\n",
    "test_df[\"prob_dogness\"] = test_df.PetID.map(test_prob_dogness)\n",
    "test_df[\"prob_catness\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0219cba5be481398bfd01aaf6c05373422dd6b83"
   },
   "source": [
    "## Extract Train Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d27668502ae8f6e5eeab943e2ad2b44f5258fc9"
   },
   "outputs": [],
   "source": [
    "extract_transform = image_transforms['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a9165d985d0bfa92364178167fa3009f28d5f4b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pids = train_df.PetID.values\n",
    "input_tensor = torch.zeros(1, 3, 224, 224)\n",
    "\n",
    "train_image_features = {}\n",
    "for petid in tqdm(train_pids):\n",
    "    train_img = f\"../input/train_images/{petid}-1.jpg\"\n",
    "    if not os.path.exists(train_img): continue\n",
    "    \n",
    "    train_img = Image.open(train_img)\n",
    "    train_img = extract_transform(train_img)\n",
    "    input_tensor[0, :, :, :] = train_img\n",
    "    input_tensor = input_tensor.cuda()\n",
    "    model(input_tensor)\n",
    "    train_image_features[petid] = image_features[0]\n",
    "    image_features.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86fcffba85a2ad17bddcc7c48da708c947fe08c3"
   },
   "outputs": [],
   "source": [
    "train_image_features = pd.DataFrame.from_dict(train_image_features, orient='index')\n",
    "train_image_features.columns = [f'img_nn_feat{idx}' for idx in train_image_features.columns.values]\n",
    "train_image_features = train_image_features.reset_index().rename(columns={'index':'PetID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9ac88a0ac235db84bef4f8df3003f0ca28dfbfd"
   },
   "outputs": [],
   "source": [
    "train_image_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e47ff767fbedab5a3f24f8145a6dde0e09fa7701"
   },
   "outputs": [],
   "source": [
    "train_image_features.to_csv('train_image_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d85f010c92a2c77adbe89b738f364761f1061a3"
   },
   "source": [
    "## Extract Test Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4361b3a6e853039cef4563dbd1c6074b906c24b0"
   },
   "outputs": [],
   "source": [
    "test_pids = test_df.PetID.values\n",
    "input_tensor = torch.zeros(1, 3, 224, 224)\n",
    "\n",
    "test_image_features = {}\n",
    "for petid in tqdm(test_pids):\n",
    "    test_img = f\"../input/test_images/{petid}-1.jpg\"\n",
    "    if not os.path.exists(test_img): continue\n",
    "    \n",
    "    test_img = Image.open(test_img)\n",
    "    test_img = extract_transform(test_img)\n",
    "    input_tensor[0, :, :, :] = test_img\n",
    "    input_tensor = input_tensor.cuda()\n",
    "    model(input_tensor)\n",
    "    test_image_features[petid] = image_features[0]\n",
    "    image_features.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4940a419c57141c936c62320c4f060ddf0b998b"
   },
   "outputs": [],
   "source": [
    "test_image_features = pd.DataFrame.from_dict(test_image_features, orient='index')\n",
    "test_image_features.columns = [f'img_nn_feat{idx}' for idx in test_image_features.columns.values]\n",
    "test_image_features = test_image_features.reset_index().rename(columns={'index':'PetID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e19a3c5b0032e5f5ea02298acec41b2e5edd86e"
   },
   "outputs": [],
   "source": [
    "test_image_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e792e50a78042cee48c6d5813d01566ef727dac"
   },
   "outputs": [],
   "source": [
    "test_image_features.to_csv('test_image_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0a3f60a0a35379869f4b27bf2385f9e76f599d1"
   },
   "source": [
    "We save the features as a csv to disk, so others can link and join the data frame with their train.csv and test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "baf8b4294611bf96c709ead0b91f5ebf4846fd8f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
